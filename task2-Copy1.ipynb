{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "470284be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensimNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/6f/a690547cb7089d4019465bfbfbbb8bea5b3e52969cd2d6005049e6678ec4/gensim-4.2.0-cp37-cp37m-win_amd64.whl (24.0MB)\n",
      "Collecting Cython==0.29.28 (from gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/9f/79/311cfbca90332ab37ef8ea08f1af3266f20a9a0e7a1d652842db832226bb/Cython-0.29.28-py2.py3-none-any.whl (983kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\paltu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gensim) (1.21.6)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\paltu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gensim) (1.7.3)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/d9/d97f1db64b09278aba64e8c81b5d322d436132df5741c518f3823824fae0/smart_open-6.4.0-py3-none-any.whl (57kB)\n",
      "Installing collected packages: Cython, smart-open, gensim\n",
      "Successfully installed Cython-0.29.28 gensim-4.2.0 smart-open-6.4.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 23.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb4b523a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting word2vec\n",
      "  Downloading https://files.pythonhosted.org/packages/11/9e/dc6d96578191b6167cb1ea4a3fe3edeed0dce54d3db21ada013b2b407d65/word2vec-0.11.1.tar.gz (42kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: joblib in c:\\users\\paltu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from word2vec) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\paltu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from word2vec) (1.21.6)\n",
      "Building wheels for collected packages: word2vec\n",
      "  Building wheel for word2vec (PEP 517): started\n",
      "  Building wheel for word2vec (PEP 517): finished with status 'done'\n",
      "  Created wheel for word2vec: filename=word2vec-0.11.1-cp37-none-any.whl size=179688 sha256=972dc329fa6f87fd028cb9e4eb9435b75e616ddd136deb0f73b887e8e83fe8ee\n",
      "  Stored in directory: C:\\Users\\paltu\\AppData\\Local\\pip\\Cache\\wheels\\f3\\7c\\ac\\fcb6d867f806021c3730fd848970db988b1d0030b5d20c0e02\n",
      "Successfully built word2vec\n",
      "Installing collected packages: word2vec\n",
      "Successfully installed word2vec-0.11.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 23.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67955eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 23.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\paltu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\paltu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\paltu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in c:\\users\\paltu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\paltu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48402a36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how company compares to its peers?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the detailed income statement breakdow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>world premium penetration in 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the forecasted insurance premium pene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what are the total losses for companies in cou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Phrases\n",
       "0                 how company compares to its peers?\n",
       "1  what is the detailed income statement breakdow...\n",
       "2                  world premium penetration in 2020\n",
       "3  How does the forecasted insurance premium pene...\n",
       "4  what are the total losses for companies in cou..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv(\"phrases.csv\", encoding='latin1')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3318d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest Match: how does economic profit for in country compare to others?, Distance: 0.4662\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the Word2Vec model from your directory i.e. model_path\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('model_path/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# Load phrases from the CSV file (assumes a 'phrase' column in the CSV)\n",
    "phrases_df = pd.read_csv(\"phrases.csv\", encoding='latin1')\n",
    "phrases = phrases_df['Phrases'].tolist()\n",
    "\n",
    "# Assign Word2Vec embeddings to each word in the phrases\n",
    "def get_phrase_embedding(phrase, model):\n",
    "    words = phrase.split()\n",
    "    valid_words = [word for word in words if word in model]\n",
    "    if valid_words:\n",
    "        phrase_embedding = np.mean([model[word] for word in valid_words], axis=0)\n",
    "        return phrase_embedding\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create a dictionary to store phrase embeddings\n",
    "phrase_embeddings = {}\n",
    "for phrase in phrases:\n",
    "    embedding = get_phrase_embedding(phrase, model)\n",
    "    if embedding is not None:\n",
    "        phrase_embeddings[phrase] = embedding\n",
    "\n",
    "# Batch execution: Calculate cosine similarities between all pairs of phrases\n",
    "def calculate_similarity_matrix(phrase_embeddings, phrases):\n",
    "    similarity_matrix = np.zeros((len(phrases), len(phrases)))\n",
    "    for i in range(len(phrases)):\n",
    "        for j in range(len(phrases)):\n",
    "            similarity = cosine_similarity([phrase_embeddings[phrases[i]]], [phrase_embeddings[phrases[j]]])[0][0]\n",
    "            similarity_matrix[i][j] = similarity\n",
    "    return similarity_matrix\n",
    "\n",
    "similarity_matrix = calculate_similarity_matrix(phrase_embeddings, phrases)\n",
    "\n",
    "# On-the-fly execution: Find the closest match to a user-input phrase\n",
    "def find_closest_match(user_input, phrase_embeddings, phrases):\n",
    "    user_embedding = get_phrase_embedding(user_input, model)\n",
    "    if user_embedding is not None:\n",
    "        similarities = [cosine_similarity([user_embedding], [phrase_embeddings[phrase]])[0][0] for phrase in phrases]\n",
    "        closest_match_idx = np.argmax(similarities)\n",
    "        closest_match = phrases[closest_match_idx]\n",
    "        distance = 1 - similarities[closest_match_idx]\n",
    "        return closest_match, distance\n",
    "    else:\n",
    "        return \"User input has no valid words for embeddings.\", None\n",
    "\n",
    "# Example usage\n",
    "user_input = \"I need help with data analysis\"\n",
    "closest_match, distance = find_closest_match(user_input, phrase_embeddings, phrases)\n",
    "print(f\"Closest Match: {closest_match}, Distance: {distance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08803248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12e55b07",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "202b7790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest Match: Show me all the oil rigs in the world, Distance: 0.1418\n"
     ]
    }
   ],
   "source": [
    "user_input = \"oil rigs in the world\"\n",
    "closest_match, distance = find_closest_match(user_input, phrase_embeddings, phrases)\n",
    "print(f\"Closest Match: {closest_match}, Distance: {distance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "816e5425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest Match: how company compares to its peers?, Distance: 0.1062\n"
     ]
    }
   ],
   "source": [
    "user_input = \"how comapny compares to its peer\"\n",
    "closest_match, distance = find_closest_match(user_input, phrase_embeddings, phrases)\n",
    "print(f\"Closest Match: {closest_match}, Distance: {distance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21c999d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest Match: Insurance premiums market in Country, Distance: 0.4076\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Brazilian Insurance mArket\"\n",
    "closest_match, distance = find_closest_match(user_input, phrase_embeddings, phrases)\n",
    "print(f\"Closest Match: {closest_match}, Distance: {distance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c30ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d5cdf40",
   "metadata": {},
   "source": [
    "**Tkinter GUI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e603428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "# Load the Word2Vec model\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('C:/Users/paltu/anaconda_copy/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# Load phrases from the CSV file (assumes a 'phrase' column in the CSV)\n",
    "phrases_df = pd.read_csv(\"phrases.csv\", encoding='latin1')\n",
    "phrases = phrases_df['Phrases'].tolist()\n",
    "\n",
    "# Assign Word2Vec embeddings to each word in the phrases\n",
    "def get_phrase_embedding(phrase, model):\n",
    "    words = phrase.split()\n",
    "    valid_words = [word for word in words if word in model]\n",
    "    if valid_words:\n",
    "        phrase_embedding = np.mean([model[word] for word in valid_words], axis=0)\n",
    "        return phrase_embedding\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create a dictionary to store phrase embeddings\n",
    "phrase_embeddings = {}\n",
    "for phrase in phrases:\n",
    "    embedding = get_phrase_embedding(phrase, model)\n",
    "    if embedding is not None:\n",
    "        phrase_embeddings[phrase] = embedding\n",
    "\n",
    "# On-the-fly execution: Find the closest match to a user-input phrase\n",
    "def find_closest_match(user_input, phrase_embeddings, phrases):\n",
    "    user_embedding = get_phrase_embedding(user_input, model)\n",
    "    if user_embedding is not None:\n",
    "        similarities = [cosine_similarity([user_embedding], [phrase_embeddings[phrase]])[0][0] for phrase in phrases]\n",
    "        closest_match_idx = np.argmax(similarities)\n",
    "        closest_match = phrases[closest_match_idx]\n",
    "        distance = 1 - similarities[closest_match_idx]\n",
    "        return closest_match, distance\n",
    "    else:\n",
    "        return \"User input has no valid words for embeddings.\", None\n",
    "\n",
    "# Tkinter GUI\n",
    "def find_closest_match_gui():\n",
    "    user_input = user_input_entry.get()\n",
    "    closest_match, distance = find_closest_match(user_input, phrase_embeddings, phrases)\n",
    "    result_label.config(text=f\"Closest Match: {closest_match}\\nDistance: {distance:.4f}\")\n",
    "\n",
    "app = tk.Tk()\n",
    "app.title(\"Word2Vec Phrase Similarity -- Made by Tushar Pal\")\n",
    "\n",
    "user_input_label = ttk.Label(app, text=\"Enter a phrase:\")\n",
    "user_input_label.pack(pady=10)\n",
    "\n",
    "user_input_entry = ttk.Entry(app)\n",
    "user_input_entry.pack()\n",
    "\n",
    "find_button = ttk.Button(app, text=\"Find Closest Match\", command=find_closest_match_gui)\n",
    "find_button.pack(pady=10)\n",
    "\n",
    "result_label = ttk.Label(app, text=\"\")\n",
    "result_label.pack()\n",
    "\n",
    "app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b7dd55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
